{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *        # Quick access to most common functionality\n",
    "from fastai.text import *   # Quick access to NLP functionality\n",
    "from pathlib import Path\n",
    "\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "file_path = '/home/ubuntu/data/autopsy/data.csv'\n",
    "\n",
    "\n",
    "data = pd.read_csv(file_path,\n",
    "                          header=None, encoding='ISO-8859-1',\n",
    "                          names=['label', 'text'])\n",
    "\n",
    "data = data.loc[data['label'].isin(['Suicide','Homicide'])]\n",
    "data.label = pd.Categorical(data.label)\n",
    "data['label_code'] = data.label.cat.codes\n",
    "\n",
    "\n",
    "X = data['text'].values\n",
    "\n",
    "Y = data['label_code'].values\n",
    "print(Y)\n",
    "print(data['label'].values)\n",
    "\n",
    "kfold_splits = 5\n",
    "kf = StratifiedKFold(n_splits=kfold_splits, shuffle=True, random_state=42)\n",
    "\n",
    "history = []\n",
    "for index, (train_indices, test_indices) in enumerate(kf.split(data['text'],data['label'])):\n",
    "  xtrain, xtest = X[train_indices], X[test_indices]\n",
    "  ytrain, ytest = Y[train_indices], Y[test_indices]\n",
    "\n",
    "\n",
    "  vectorizer = CountVectorizer(stop_words='english')\n",
    "  \n",
    "  train_features = vectorizer.fit_transform(xtrain)\n",
    "  test_features = vectorizer.transform(xtest)\n",
    "  \n",
    "\n",
    "  nb = MultinomialNB()\n",
    "  nb.fit(train_features, ytrain)\n",
    "\n",
    "\n",
    "  predictions = nb.predict(test_features)\n",
    "  accuracy = accuracy_score(ytest,predictions)\n",
    "  history.append(accuracy)\n",
    "  print (accuracy)\n",
    "print(history)\n",
    "\n",
    "sum = 0.0\n",
    "for acc in history:\n",
    "  sum = sum + acc\n",
    "print ('average accuracy:', (sum/(kfold_splits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic RNN LSTM (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.python.keras.layers import Input, LSTM, Bidirectional, Dense, Embedding, Dropout, SpatialDropout1D, GRU\n",
    "from keras import optimizers\n",
    "import sys\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "\n",
    "file_path = '/home/ubuntu/data/autopsy/data.csv'\n",
    "\n",
    "\n",
    "data = pd.read_csv(file_path,\n",
    "                          header=None, encoding='ISO-8859-1',\n",
    "                          names=['label', 'text'])\n",
    "\n",
    "data = data.loc[data['label'].isin(['Suicide','Homicide'])]\n",
    "max_features = 2000\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "X = pad_sequences(X)\n",
    "Y = pd.get_dummies(data['label']).values\n",
    "\n",
    "print(Y.shape)\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "\n",
    "maxlen = X.shape[1]\n",
    "embedding_size=300\n",
    "batch_size = 32\n",
    "lstm_out = 196\n",
    "\n",
    "def make_model(batch_size=None):\n",
    "  source = Input(shape=(maxlen,), batch_size=batch_size, dtype=tf.int32, name='Input')\n",
    "  embedding = Embedding(input_dim=max_features, output_dim=embedding_size, input_length = X.shape[1],name='Embedding')(source)\n",
    "  drop = SpatialDropout1D(0.5)(embedding)\n",
    "  #rnn =  Bidirectional(LSTM(lstm_out, name = 'LSTM',dropout=0.50, recurrent_dropout=0.50))(drop)\n",
    "  rnn =  LSTM(lstm_out, name = 'LSTM',dropout=0.40, recurrent_dropout=0.40)(drop)\n",
    "  predicted_var = Dense(2, activation='sigmoid', name='Output')(rnn)\n",
    "  model = tf.keras.Model(inputs=[source], outputs=[predicted_var])\n",
    "  model.compile(\n",
    "      optimizer='adam',\n",
    "      #optimizer=tf.keras.optimizers.RMSprop(decay=1e-3),\n",
    "      loss = 'categorical_crossentropy',\n",
    "      metrics=['acc'])\n",
    "  return model\n",
    "\n",
    "history_list = []\n",
    "\n",
    "eval_history_list = []\n",
    "\n",
    "kfold_splits = 5\n",
    "kf = KFold(n_splits=kfold_splits, shuffle=True)\n",
    "\n",
    "for index, (train_indices, val_indices) in enumerate(kf.split(data['text'],data['label'])):\n",
    "  xtrain, xval = X[train_indices], X[val_indices]\n",
    "  ytrain, yval = Y[train_indices], Y[val_indices]\n",
    "  \n",
    "  tf.keras.backend.clear_session()\n",
    "  training_model = None\n",
    "  #training_model = make_model(batch_size = batch_size)\n",
    "  training_model = make_model()\n",
    "  \n",
    "  \n",
    "  history = training_model.fit(xtrain, ytrain,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(xval,yval))\n",
    "  \n",
    "  history_list.append(history)\n",
    "\n",
    "  accuracy_history = history.history['acc']\n",
    "  val_accuracy_history = history.history['val_acc']\n",
    "  print (\"Last training accuracy: \" + str(accuracy_history[-1]) + \", last validation accuracy: \" + str(val_accuracy_history[-1]) )\n",
    "  \n",
    "  eval_history = training_model.evaluate(xval, yval, batch_size=batch_size)\n",
    "  eval_history_list.append(eval_history[1])\n",
    "\n",
    "  print (\"Evaluate:\")\n",
    "  print(eval_history)\n",
    " \n",
    "sum = 0.0\n",
    "for h in history_list:\n",
    "  val_accuracy_history = h.history['val_acc']\n",
    "  final_val_accuracy = val_accuracy_history[-1]\n",
    "  sum = sum + final_val_accuracy\n",
    "\n",
    "print('')\n",
    "print(eval_history_list)\n",
    "print('')\n",
    "print(\"average accuracy:\", (sum/(kfold_splits)))\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple RNN using an AWD LSTM activation (trained from scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter setting 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "\n",
    "batch_size=32\n",
    "\n",
    "drop_mult=0.1\n",
    "learning_rate= slice(1e-5,1e-3)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "i = 0\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  print(\"\\nFold: \" + str(i))\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, max_vocab=2000, classes=['Suicide','Homicide'], bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult, emb_sz=300, nh=198, nl=1)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "    \n",
    "  learner_list.append(learn)\n",
    "\n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ (num_folds  ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter setting 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.5\n",
    "learning_rate= slice(1e-5,1e-3)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "i = 0\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  print(\"\\nFold: \" + str(i))\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, max_vocab=2000, classes=['Suicide','Homicide'], bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult, emb_sz=300, nh=198, nl=1)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "    \n",
    "  learner_list.append(learn)\n",
    "\n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ (num_folds ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter setting 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.3\n",
    "learning_rate= slice(1e-4,1e-3)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "i = 0\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  print(\"\\nFold: \" + str(i))\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, max_vocab=2000, classes=['Suicide','Homicide'], bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult, emb_sz=300, nh=198, nl=1)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "    \n",
    "  learner_list.append(learn)\n",
    "\n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ (num_folds  ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter setting 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.3\n",
    "learning_rate= slice(1e-4,1e-2)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "i = 0\n",
    "for index, f in folds:\n",
    "  i = i + 1\n",
    "  print(\"\\nFold: \" + str(i))\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, max_vocab=2000, classes=['Suicide','Homicide'], bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult, emb_sz=300, nh=198, nl=1)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "    \n",
    "  learner_list.append(learn)\n",
    "\n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ (num_folds  ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Large RNN using an AWD LSTM activation (trained from scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter setting 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.1\n",
    "learning_rate= slice(1e-5,1e-3)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "i = 0\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  print(\"\\nFold: \" + str(i))\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, classes=['Suicide','Homicide'],bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "  learner_list.append(learn)\n",
    "  \n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ (num_folds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter setting 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.5\n",
    "learning_rate= slice(1e-5,1e-3)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "i = 0\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  print(\"\\nFold: \" + str(i))\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, classes=['Suicide','Homicide'],bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "  learner_list.append(learn)\n",
    "  \n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ (num_folds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter setting 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.3\n",
    "learning_rate= slice(1e-4,1e-3)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "i = 0\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  print(\"\\nFold: \" + str(i))\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, classes=['Suicide','Homicide'],bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "  learner_list.append(learn)\n",
    "  \n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ (num_folds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter setting 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.3\n",
    "learning_rate= slice(1e-4,1e-2)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "i = 0\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  print(\"\\nFold: \" + str(i))\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, classes=['Suicide','Homicide'],bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "  learner_list.append(learn)\n",
    "  \n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ (num_folds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Large RNN using an AWD LSTM activation (pretrained with WikiText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter setting 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "path_lm = Path('/home/ubuntu/data/autopsy')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.1\n",
    "learning_rate= slice(1e-5,1e-3)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "i = 0\n",
    "data_lm = TextLMDataBunch.from_csv(path_lm, 'data_suicide_homicide_k_1.csv', classes=['Suicide','Homicide'])\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  print(\"\\nFold: \" + str(i))\n",
    "  #data_lm = TextLMDataBunch.from_csv(path_lm, f, classes=['Suicide','Homicide'])\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, vocab=data_lm.train_ds.vocab, classes=['Suicide','Homicide'], bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "  learn.load_encoder('enc_autopsy_only_pretrained')\n",
    "  learn.fit(4,learning_rate, wd=wd)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "  learner_list.append(learn)\n",
    "  \n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ (num_folds ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter setting 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "path_lm = Path('/home/ubuntu/data/autopsy')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.5\n",
    "learning_rate= slice(1e-5,1e-3)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "i = 0\n",
    "data_lm = TextLMDataBunch.from_csv(path_lm, 'data_suicide_homicide_k_1.csv', classes=['Suicide','Homicide'])\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  print(\"\\nFold: \" + str(i))\n",
    "  #data_lm = TextLMDataBunch.from_csv(path_lm, f, classes=['Suicide','Homicide'])\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, vocab=data_lm.train_ds.vocab, classes=['Suicide','Homicide'], bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "  learn.load_encoder('enc_autopsy_only_pretrained')\n",
    "  learn.fit(4,learning_rate, wd=wd)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "  learner_list.append(learn)\n",
    "  \n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ (num_folds ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter setting 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "path_lm = Path('/home/ubuntu/data/autopsy')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.3\n",
    "learning_rate= slice(1e-4,1e-3)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "i = 0\n",
    "data_lm = TextLMDataBunch.from_csv(path_lm, 'data_suicide_homicide_k_1.csv', classes=['Suicide','Homicide'])\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  print(\"\\nFold: \" + str(i))\n",
    "  #data_lm = TextLMDataBunch.from_csv(path_lm, f, classes=['Suicide','Homicide'])\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, vocab=data_lm.train_ds.vocab, classes=['Suicide','Homicide'], bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "  learn.load_encoder('enc_autopsy_only_pretrained')\n",
    "  learn.fit(4,learning_rate, wd=wd)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "  learner_list.append(learn)\n",
    "  \n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ (num_folds ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter setting 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "path_lm = Path('/home/ubuntu/data/autopsy')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.3\n",
    "learning_rate= slice(1e-4,1e-2)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "i = 0\n",
    "data_lm = TextLMDataBunch.from_csv(path_lm, 'data_suicide_homicide_k_1.csv', classes=['Suicide','Homicide'])\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  print(\"\\nFold: \" + str(i))\n",
    "  #data_lm = TextLMDataBunch.from_csv(path_lm, f, classes=['Suicide','Homicide'])\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, vocab=data_lm.train_ds.vocab, classes=['Suicide','Homicide'], bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "  learn.load_encoder('enc_autopsy_only_pretrained')\n",
    "  learn.fit(4,learning_rate, wd=wd)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "  learner_list.append(learn)\n",
    "  \n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ (num_folds ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Large RNN using an AWD LSTM activation (finetuned with the autopsy data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter settings 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "path_lm = Path('/home/ubuntu/data/autopsy')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.1\n",
    "learning_rate= slice(1e-5,1e-3)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "\n",
    "i = 0\n",
    "data_lm = TextLMDataBunch.from_csv(path_lm, 'data_suicide_homicide_k_1.csv', classes=['Suicide','Homicide'])\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  \n",
    "  #data_lm = TextLMDataBunch.from_csv(path_lm, 'data_suicide_homicide_k_1.csv', classes=['Suicide','Homicide'])\n",
    "\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, vocab=data_lm.train_ds.vocab, classes=['Suicide','Homicide'], bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "  learn.load_encoder('enc_autopsy_not_pretrained')\n",
    "  learn.fit(4,learning_rate, wd=wd)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "  learner_list.append(learn)\n",
    "  \n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ (num_folds ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter settings 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "path_lm = Path('/home/ubuntu/data/autopsy')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.5\n",
    "learning_rate= slice(1e-5,1e-3)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "\n",
    "i = 0\n",
    "data_lm = TextLMDataBunch.from_csv(path_lm, 'data_suicide_homicide_k_1.csv', classes=['Suicide','Homicide'])\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  \n",
    "  #data_lm = TextLMDataBunch.from_csv(path_lm, 'data_suicide_homicide_k_1.csv', classes=['Suicide','Homicide'])\n",
    "\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, vocab=data_lm.train_ds.vocab, classes=['Suicide','Homicide'], bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "  learn.load_encoder('enc_autopsy_not_pretrained')\n",
    "  learn.fit(4,learning_rate, wd=wd)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "  learner_list.append(learn)\n",
    "  \n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ (num_folds ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter settings 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "path_lm = Path('/home/ubuntu/data/autopsy')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.3\n",
    "learning_rate= slice(1e-4,1e-3)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "\n",
    "i = 0\n",
    "data_lm = TextLMDataBunch.from_csv(path_lm, 'data_suicide_homicide_k_1.csv', classes=['Suicide','Homicide'])\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  \n",
    "  #data_lm = TextLMDataBunch.from_csv(path_lm, 'data_suicide_homicide_k_1.csv', classes=['Suicide','Homicide'])\n",
    "\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, vocab=data_lm.train_ds.vocab, classes=['Suicide','Homicide'], bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "  learn.load_encoder('enc_autopsy_not_pretrained')\n",
    "  learn.fit(4,learning_rate, wd=wd)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "  learner_list.append(learn)\n",
    "  \n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ (num_folds ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter settings 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "path_lm = Path('/home/ubuntu/data/autopsy')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.3\n",
    "learning_rate= slice(1e-4,1e-2)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "\n",
    "i = 0\n",
    "data_lm = TextLMDataBunch.from_csv(path_lm, 'data_suicide_homicide_k_1.csv', classes=['Suicide','Homicide'])\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  \n",
    "  #data_lm = TextLMDataBunch.from_csv(path_lm, 'data_suicide_homicide_k_1.csv', classes=['Suicide','Homicide'])\n",
    "\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, vocab=data_lm.train_ds.vocab, classes=['Suicide','Homicide'], bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "  learn.load_encoder('enc_autopsy_not_pretrained')\n",
    "  learn.fit(4,learning_rate, wd=wd)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "  learner_list.append(learn)\n",
    "  \n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ (num_folds ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Large RNN using an AWD LSTM activation (finetuned with the Nidia27k data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter settings 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "path_lm = Path('/home/ubuntu/data/medical/nidia27k_preprocess')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.1\n",
    "learning_rate=slice(1e-5,1e-3)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "i = 0\n",
    "data_lm = TextLMDataBunch.from_csv(path_lm,'documents-preprocess-valid.csv', classes=['neg','pos'], bs=batch_size)\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  print(\"\\nFold: \" + str(i))\n",
    "  #data_lm = TextLMDataBunch.from_csv(path_lm, f, classes=['Suicide','Homicide'])\n",
    "  #data_lm = TextLMDataBunch.from_csv(path_lm,'documents-preprocess-valid.csv', classes=['neg','pos'], bs=batch_size)\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, vocab=data_lm.train_ds.vocab, classes=['Suicide','Homicide'], bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "  learn.load_encoder('enc_nidia_not_pretrained')\n",
    "  learn.fit(4,learning_rate, wd=wd)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "  \n",
    "  learner_list.append(learn)  \n",
    "    \n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ (num_folds ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter settings 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "path_lm = Path('/home/ubuntu/data/medical/nidia27k_preprocess')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.5\n",
    "learning_rate=slice(1e-5,1e-3)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "i = 0\n",
    "data_lm = TextLMDataBunch.from_csv(path_lm,'documents-preprocess-valid.csv', classes=['neg','pos'], bs=batch_size)\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  print(\"\\nFold: \" + str(i))\n",
    "  #data_lm = TextLMDataBunch.from_csv(path_lm, f, classes=['Suicide','Homicide'])\n",
    "  #data_lm = TextLMDataBunch.from_csv(path_lm,'documents-preprocess-valid.csv', classes=['neg','pos'], bs=batch_size)\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, vocab=data_lm.train_ds.vocab, classes=['Suicide','Homicide'], bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "  learn.load_encoder('enc_nidia_not_pretrained')\n",
    "  learn.fit(4,learning_rate, wd=wd)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "  \n",
    "  learner_list.append(learn)  \n",
    "    \n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ (num_folds ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter settings 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "path_lm = Path('/home/ubuntu/data/medical/nidia27k_preprocess')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.3\n",
    "learning_rate=slice(1e-4,1e-3)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "i = 0\n",
    "data_lm = TextLMDataBunch.from_csv(path_lm,'documents-preprocess-valid.csv', classes=['neg','pos'], bs=batch_size)\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  print(\"\\nFold: \" + str(i))\n",
    "  #data_lm = TextLMDataBunch.from_csv(path_lm, f, classes=['Suicide','Homicide'])\n",
    "  #data_lm = TextLMDataBunch.from_csv(path_lm,'documents-preprocess-valid.csv', classes=['neg','pos'], bs=batch_size)\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, vocab=data_lm.train_ds.vocab, classes=['Suicide','Homicide'], bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "  learn.load_encoder('enc_nidia_not_pretrained')\n",
    "  learn.fit(4,learning_rate, wd=wd)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "  \n",
    "  learner_list.append(learn)  \n",
    "    \n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ (num_folds ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter settings 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "path_lm = Path('/home/ubuntu/data/medical/nidia27k_preprocess')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.3\n",
    "learning_rate=slice(1e-4,1e-2)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "i = 0\n",
    "data_lm = TextLMDataBunch.from_csv(path_lm,'documents-preprocess-valid.csv', classes=['neg','pos'], bs=batch_size)\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  print(\"\\nFold: \" + str(i))\n",
    "  #data_lm = TextLMDataBunch.from_csv(path_lm, f, classes=['Suicide','Homicide'])\n",
    "  #data_lm = TextLMDataBunch.from_csv(path_lm,'documents-preprocess-valid.csv', classes=['neg','pos'], bs=batch_size)\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, vocab=data_lm.train_ds.vocab, classes=['Suicide','Homicide'], bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "  learn.load_encoder('enc_nidia_not_pretrained')\n",
    "  learn.fit(4,learning_rate, wd=wd)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "  \n",
    "  learner_list.append(learn)  \n",
    "    \n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ (float(num_folds)  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Large RNN using an AWD LSTM activation (pretrained with WikiText and finetuned with the autopsy data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter settings 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "path_lm = Path('/home/ubuntu/data/autopsy')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.1\n",
    "learning_rate=slice(1e-5,1e-3)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "i = 0\n",
    "data_lm = TextLMDataBunch.from_csv(path_lm, 'data_suicide_homicide_k_1.csv', classes=['Suicide','Homicide'])\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  print(\"\\nFold: \" + str(i))\n",
    "  #data_lm = TextLMDataBunch.from_csv(path_lm, f, classes=['Suicide','Homicide'])\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, vocab=data_lm.train_ds.vocab, classes=['Suicide','Homicide'], bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "  learn.load_encoder('enc_autopsy_pretrained')\n",
    "  learn.fit(4,learning_rate, wd=wd)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "  learner_list.append(learn)\n",
    "  \n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ num_folds  ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter settings 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "path_lm = Path('/home/ubuntu/data/autopsy')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.5\n",
    "learning_rate=slice(1e-5,1e-3)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "i = 0\n",
    "data_lm = TextLMDataBunch.from_csv(path_lm, 'data_suicide_homicide_k_1.csv', classes=['Suicide','Homicide'])\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  print(\"\\nFold: \" + str(i))\n",
    "  #data_lm = TextLMDataBunch.from_csv(path_lm, f, classes=['Suicide','Homicide'])\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, vocab=data_lm.train_ds.vocab, classes=['Suicide','Homicide'], bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "  learn.load_encoder('enc_autopsy_pretrained')\n",
    "  learn.fit(4,learning_rate, wd=wd)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "  learner_list.append(learn)\n",
    "  \n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ num_folds  ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter settings 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "path_lm = Path('/home/ubuntu/data/autopsy')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.3\n",
    "learning_rate=slice(1e-4,1e-3)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "i = 0\n",
    "data_lm = TextLMDataBunch.from_csv(path_lm, 'data_suicide_homicide_k_1.csv', classes=['Suicide','Homicide'])\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  print(\"\\nFold: \" + str(i))\n",
    "  #data_lm = TextLMDataBunch.from_csv(path_lm, f, classes=['Suicide','Homicide'])\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, vocab=data_lm.train_ds.vocab, classes=['Suicide','Homicide'], bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "  learn.load_encoder('enc_autopsy_pretrained')\n",
    "  learn.fit(4,learning_rate, wd=wd)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "  learner_list.append(learn)\n",
    "  \n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ num_folds  ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter settings 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "path_lm = Path('/home/ubuntu/data/autopsy')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.3\n",
    "learning_rate=slice(1e-4,1e-2)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "i = 0\n",
    "data_lm = TextLMDataBunch.from_csv(path_lm, 'data_suicide_homicide_k_1.csv', classes=['Suicide','Homicide'])\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  print(\"\\nFold: \" + str(i))\n",
    "  #data_lm = TextLMDataBunch.from_csv(path_lm, f, classes=['Suicide','Homicide'])\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, vocab=data_lm.train_ds.vocab, classes=['Suicide','Homicide'], bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "  learn.load_encoder('enc_autopsy_pretrained')\n",
    "  learn.fit(4,learning_rate, wd=wd)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "  learner_list.append(learn)\n",
    "  \n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ num_folds  ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Large RNN using an AWD LSTM activation (pretrained with WikiText and finetuned with the Nidia27k data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter settings 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "path_lm = Path('/home/ubuntu/data/medical/nidia27k_preprocess')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.1\n",
    "learning_rate=slice(1e-5,1e-3)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "i = 0\n",
    "data_lm = TextLMDataBunch.from_csv(path_lm, 'documents-preprocess-valid.csv', classes=['neg','pos'])\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  print(\"\\nFold: \" + str(i))\n",
    "  #data_lm = TextLMDataBunch.from_csv(path_lm, f, classes=['neg','pos'])\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, vocab=data_lm.train_ds.vocab, classes=['Suicide','Homicide'],bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "  learn.load_encoder('enc_nidia_pretrained')\n",
    "  learn.fit(4,learning_rate, wd=wd)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "  learner_list.append(learn)\n",
    "  \n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ (num_folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter settings 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "path_lm = Path('/home/ubuntu/data/medical/nidia27k_preprocess')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.5\n",
    "learning_rate=slice(1e-5,1e-3)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "i = 0\n",
    "data_lm = TextLMDataBunch.from_csv(path_lm, 'documents-preprocess-valid.csv', classes=['neg','pos'])\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  print(\"\\nFold: \" + str(i))\n",
    "  #data_lm = TextLMDataBunch.from_csv(path_lm, f, classes=['neg','pos'])\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, vocab=data_lm.train_ds.vocab, classes=['Suicide','Homicide'],bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "  learn.load_encoder('enc_nidia_pretrained')\n",
    "  learn.fit(4,learning_rate, wd=wd)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "  learner_list.append(learn)\n",
    "  \n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ (num_folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter settings 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "path_lm = Path('/home/ubuntu/data/medical/nidia27k_preprocess')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.3\n",
    "learning_rate=slice(1e-4,1e-3)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "i = 0\n",
    "data_lm = TextLMDataBunch.from_csv(path_lm, 'documents-preprocess-valid.csv', classes=['neg','pos'])\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  print(\"\\nFold: \" + str(i))\n",
    "  #data_lm = TextLMDataBunch.from_csv(path_lm, f, classes=['neg','pos'])\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, vocab=data_lm.train_ds.vocab, classes=['Suicide','Homicide'],bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "  learn.load_encoder('enc_nidia_pretrained')\n",
    "  learn.fit(4,learning_rate, wd=wd)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "  learner_list.append(learn)\n",
    "  \n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ (num_folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter settings 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = Path('/home/ubuntu/data/autopsy')\n",
    "path_lm = Path('/home/ubuntu/data/medical/nidia27k_preprocess')\n",
    "\n",
    "batch_size=32\n",
    "drop_mult=0.3\n",
    "learning_rate=slice(1e-4,1e-2)\n",
    "wd=1e-4\n",
    "num_folds = 5\n",
    "\n",
    "moms = (0.8,0.7)\n",
    "folds = ['data_suicide_homicide_k_1.csv','data_suicide_homicide_k_2.csv','data_suicide_homicide_k_3.csv','data_suicide_homicide_k_4.csv','data_suicide_homicide_k_5.csv']\n",
    "\n",
    "accuracy_list = []\n",
    "learner_list = []\n",
    "i = 0\n",
    "data_lm = TextLMDataBunch.from_csv(path_lm, 'documents-preprocess-valid.csv', classes=['neg','pos'])\n",
    "for f in folds:\n",
    "  i = i + 1\n",
    "  print(\"\\nFold: \" + str(i))\n",
    "  #data_lm = TextLMDataBunch.from_csv(path_lm, f, classes=['neg','pos'])\n",
    "  data_clas = TextClasDataBunch.from_csv(path_clas,f, vocab=data_lm.train_ds.vocab, classes=['Suicide','Homicide'],bs=batch_size)\n",
    "\n",
    "  learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "  learn.load_encoder('enc_nidia_pretrained')\n",
    "  learn.fit(4,learning_rate, wd=wd)\n",
    "  learn.unfreeze()\n",
    "  learn.fit_one_cycle(epochs,learning_rate, wd=wd, moms=moms)\n",
    "  learner_list.append(learn)\n",
    "  \n",
    "  acc = (learn.validate())[1].item()\n",
    "  accuracy_list.append(acc)\n",
    "\n",
    "print('\\nAccuracy List')\n",
    "print(accuracy_list)\n",
    "\n",
    "print(\"\\nAverage Accuracy\")\n",
    "print( (sum(accuracy_list))/ (num_folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[0].recorder.plot_losses()\n",
    "learner_list[0].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[1].recorder.plot_losses()\n",
    "learner_list[1].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[2].recorder.plot_losses()\n",
    "learner_list[2].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[3].recorder.plot_losses()\n",
    "learner_list[3].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_list[4].recorder.plot_losses()\n",
    "learner_list[4].recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
