epoch  train_loss  valid_loss  accuracy
1      4.683354    4.724717    0.258230
2      4.664480    4.635316    0.266165
3      4.558451    4.583095    0.270310
4      4.578845    4.566209    0.272579
5      4.529479    4.550161    0.273820
6      4.524248    4.520613    0.275285
7      4.570425    4.534054    0.275287
8      4.523328    4.512579    0.276358
9      4.424267    4.518567    0.276890
10     4.539001    4.509111    0.277119
11     4.510419    4.514140    0.277139
12     4.493747    4.506993    0.277898
13     4.525690    4.500997    0.278231
14     4.493873    4.498724    0.278312
15     4.397334    4.493141    0.279367
16     4.510909    4.489309    0.279175
17     4.444581    4.489091    0.279096
18     4.487998    4.486601    0.279462
19     4.518101    4.487249    0.279473
20     4.448820    4.478507    0.280578
21     4.516231    4.476579    0.280233
22     4.475323    4.481058    0.279741
23     4.403676    4.468457    0.281461
24     4.457576    4.468299    0.280305
25     4.439921    4.483407    0.280003
26     4.427060    4.481338    0.280719
27     4.544412    4.471437    0.281551
28     4.410516    4.471745    0.281261
29     4.463292    4.476103    0.280431
30     4.533196    4.467867    0.281628
31     4.451724    4.486040    0.280311
32     4.385549    4.477768    0.281632
33     4.374334    4.466902    0.281886
34     4.489356    4.471806    0.281526
35     4.435848    4.463359    0.281250
36     4.422882    4.454267    0.281305
37     4.463525    4.455872    0.282915
38     4.433991    4.458971    0.281964
39     4.419502    4.455905    0.282137
40     4.388112    4.453912    0.282579
41     4.488831    4.457403    0.282029
42     4.481897    4.456570    0.282281
43     4.507533    4.446418    0.283430
44     4.453937    4.462253    0.282284
45     4.431491    4.461354    0.281650
46     4.477743    4.434688    0.283149
47     4.445935    4.448464    0.281960
48     4.417455    4.452483    0.281763
49     4.404354    4.450296    0.282897
50     4.390439    4.451373    0.282309
